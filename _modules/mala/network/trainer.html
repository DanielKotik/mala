

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>mala.network.trainer &mdash; MALA  documentation</title>
  

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="../../../_static/mala_favicon.png"/>
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home"> MALA
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Features</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../features/background.html">Background</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../features/preprocessing.html">Preprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../features/neuralnetworks.html">Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../features/postprocessing.html">Postprocessing</a></li>
</ul>
<p class="caption"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../install/README.html">Installation of MALA</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../install/INSTALL_LAMMPS.html">Setting up LAMMPS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../install/INSTALL_TE_QE.html">Python bindings to Quantum Espresso</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../install/tested_systems.html">Successfully tested on</a></li>
</ul>
<p class="caption"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../api/modules.html">mala</a></li>
</ul>
<p class="caption"><span class="caption-text">Contributing</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../CONTRIBUTE.html">Contributing to MALA</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">MALA</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
      <li>mala.network.trainer</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for mala.network.trainer</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Trainer class for training a network.&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">mala.network.network</span> <span class="kn">import</span> <span class="n">Network</span>
<span class="kn">from</span> <span class="nn">mala.datahandling.data_handler</span> <span class="kn">import</span> <span class="n">DataHandler</span>
<span class="kn">from</span> <span class="nn">mala.datahandling.data_scaler</span> <span class="kn">import</span> <span class="n">DataScaler</span>
<span class="kn">from</span> <span class="nn">mala.common.parameters</span> <span class="kn">import</span> <span class="n">Parameters</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">optim</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">mala.common.parameters</span> <span class="kn">import</span> <span class="n">printout</span>
<span class="kn">from</span> <span class="nn">.runner</span> <span class="kn">import</span> <span class="n">Runner</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">horovod.torch</span> <span class="k">as</span> <span class="nn">hvd</span>
<span class="k">except</span> <span class="ne">ModuleNotFoundError</span><span class="p">:</span>
    <span class="c1"># Warning is thrown by Parameters class</span>
    <span class="k">pass</span>
<span class="kn">import</span> <span class="nn">time</span>


<div class="viewcode-block" id="Trainer"><a class="viewcode-back" href="../../../api/mala.network.html#mala.network.trainer.Trainer">[docs]</a><span class="k">class</span> <span class="nc">Trainer</span><span class="p">(</span><span class="n">Runner</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A class for training a neural network.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">network</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">optimizer_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a Trainer object to run a Network.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        params : mala.common.parametes.Parameters</span>
<span class="sd">            Parameters used to create this Trainer object.</span>

<span class="sd">        network : mala.network.network.Network</span>
<span class="sd">            Network which is being trained.</span>

<span class="sd">        data : mala.datahandling.data_handler.DataHandler</span>
<span class="sd">            DataHandler holding the training data.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># copy the parameters into the class.</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Trainer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">network</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">final_test_loss</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initial_test_loss</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">final_validation_loss</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">initial_validation_loss</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">patience_counter</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_epoch</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_loss</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_data_loader</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">validation_data_loader</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_data_loader</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__prepare_to_train</span><span class="p">(</span><span class="n">optimizer_dict</span><span class="p">)</span>

<div class="viewcode-block" id="Trainer.resume_checkpoint"><a class="viewcode-back" href="../../../api/mala.network.html#mala.network.trainer.Trainer.resume_checkpoint">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">resume_checkpoint</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">checkpoint_name</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Prepare resumption of training from a checkpoint.</span>

<span class="sd">        Please note that to actually resume the training,</span>
<span class="sd">        Trainer.train_network() still has to be called.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        checkpoint_name : string</span>
<span class="sd">            Name of the checkpoint from which</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        loaded_params : mala.common.parameters.Parameters</span>
<span class="sd">            The Parameters saved in the checkpoint.</span>

<span class="sd">        loaded_network : mala.network.network.Network</span>
<span class="sd">            The network saved in the checkpoint.</span>

<span class="sd">        new_datahandler : mala.datahandling.data_handler.DataHandler</span>
<span class="sd">            The data handler reconstructed from the checkpoint.</span>

<span class="sd">        new_trainer : Trainer</span>
<span class="sd">            The trainer reconstructed from the checkpoint.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">printout</span><span class="p">(</span><span class="s2">&quot;Loading training run from checkpoint.&quot;</span><span class="p">)</span>
        <span class="c1"># The names are based upon the checkpoint name.</span>
        <span class="n">network_name</span> <span class="o">=</span> <span class="n">checkpoint_name</span> <span class="o">+</span> <span class="s2">&quot;_network.pth&quot;</span>
        <span class="n">iscaler_name</span> <span class="o">=</span> <span class="n">checkpoint_name</span> <span class="o">+</span> <span class="s2">&quot;_iscaler.pkl&quot;</span>
        <span class="n">oscaler_name</span> <span class="o">=</span> <span class="n">checkpoint_name</span> <span class="o">+</span> <span class="s2">&quot;_oscaler.pkl&quot;</span>
        <span class="n">param_name</span> <span class="o">=</span> <span class="n">checkpoint_name</span> <span class="o">+</span> <span class="s2">&quot;_params.pkl&quot;</span>
        <span class="n">optimizer_name</span> <span class="o">=</span> <span class="n">checkpoint_name</span> <span class="o">+</span> <span class="s2">&quot;_optimizer.pth&quot;</span>

        <span class="c1"># First load the all the regular objects.</span>
        <span class="n">loaded_params</span> <span class="o">=</span> <span class="n">Parameters</span><span class="o">.</span><span class="n">load_from_file</span><span class="p">(</span><span class="n">param_name</span><span class="p">)</span>
        <span class="n">loaded_iscaler</span> <span class="o">=</span> <span class="n">DataScaler</span><span class="o">.</span><span class="n">load_from_file</span><span class="p">(</span><span class="n">iscaler_name</span><span class="p">)</span>
        <span class="n">loaded_oscaler</span> <span class="o">=</span> <span class="n">DataScaler</span><span class="o">.</span><span class="n">load_from_file</span><span class="p">(</span><span class="n">oscaler_name</span><span class="p">)</span>
        <span class="n">loaded_network</span> <span class="o">=</span> <span class="n">Network</span><span class="o">.</span><span class="n">load_from_file</span><span class="p">(</span><span class="n">loaded_params</span><span class="p">,</span>
                                                <span class="n">network_name</span><span class="p">)</span>

        <span class="n">printout</span><span class="p">(</span><span class="s2">&quot;Preparing data used for last checkpoint.&quot;</span><span class="p">)</span>
        <span class="c1"># Create a new data handler and prepare the data.</span>
        <span class="n">new_datahandler</span> <span class="o">=</span> <span class="n">DataHandler</span><span class="p">(</span><span class="n">loaded_params</span><span class="p">,</span>
                                      <span class="n">input_data_scaler</span><span class="o">=</span><span class="n">loaded_iscaler</span><span class="p">,</span>
                                      <span class="n">output_data_scaler</span><span class="o">=</span><span class="n">loaded_oscaler</span><span class="p">)</span>
        <span class="n">new_datahandler</span><span class="o">.</span><span class="n">prepare_data</span><span class="p">(</span><span class="n">reparametrize_scaler</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">new_trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="o">.</span><span class="n">load_from_file</span><span class="p">(</span><span class="n">loaded_params</span><span class="p">,</span> <span class="n">optimizer_name</span><span class="p">,</span>
                                             <span class="n">loaded_network</span><span class="p">,</span> <span class="n">new_datahandler</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">loaded_params</span><span class="p">,</span> <span class="n">loaded_network</span><span class="p">,</span> <span class="n">new_datahandler</span><span class="p">,</span> <span class="n">new_trainer</span></div>

<div class="viewcode-block" id="Trainer.load_from_file"><a class="viewcode-back" href="../../../api/mala.network.html#mala.network.trainer.Trainer.load_from_file">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">load_from_file</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">file_path</span><span class="p">,</span> <span class="n">network</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Load a trainer from a file.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        params : mala.common.parameters.Parameters</span>
<span class="sd">            Parameters object with which the trainer should be created.</span>
<span class="sd">            Has to be compatible with network and data.</span>

<span class="sd">        file_path : string</span>
<span class="sd">            Path to the file from which the trainer should be loaded.</span>

<span class="sd">        network : mala.network.network.Network</span>
<span class="sd">            Network which is being trained.</span>

<span class="sd">        data : mala.datahandling.data_handler.DataHandler</span>
<span class="sd">            DataHandler holding the training data.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        loaded_trainer : Network</span>
<span class="sd">            The trainer that was loaded from the file.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># First, load the checkpoint.</span>
        <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span>

        <span class="c1"># Now, create the Trainer class with it.</span>
        <span class="n">loaded_trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">network</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span>
                                 <span class="n">optimizer_dict</span><span class="o">=</span><span class="n">checkpoint</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loaded_trainer</span></div>

<div class="viewcode-block" id="Trainer.train_network"><a class="viewcode-back" href="../../../api/mala.network.html#mala.network.trainer.Trainer.train_network">[docs]</a>    <span class="k">def</span> <span class="nf">train_network</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Train a network using data given by a DataHandler.&quot;&quot;&quot;</span>
        <span class="c1"># Create reference to data and network and setup training.</span>
        <span class="c1"># Calculate initial loss.</span>
        <span class="n">tloss</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span>
        <span class="n">vloss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__validate_network</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="p">,</span>
                                        <span class="bp">self</span><span class="o">.</span><span class="n">validation_data_loader</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">test_data_set</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">tloss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__validate_network</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="p">,</span>
                                            <span class="bp">self</span><span class="o">.</span><span class="n">test_data_loader</span><span class="p">)</span>

        <span class="c1"># Collect and average all the losses from all the devices</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters_full</span><span class="o">.</span><span class="n">use_horovod</span><span class="p">:</span>
            <span class="n">vloss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__average_validation</span><span class="p">(</span><span class="n">vloss</span><span class="p">,</span> <span class="s1">&#39;average_loss&#39;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">initial_validation_loss</span> <span class="o">=</span> <span class="n">vloss</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">test_data_set</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">tloss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__average_validation</span><span class="p">(</span><span class="n">tloss</span><span class="p">,</span> <span class="s1">&#39;average_loss&#39;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">initial_test_loss</span> <span class="o">=</span> <span class="n">tloss</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">verbosity</span><span class="p">:</span>
            <span class="n">printout</span><span class="p">(</span><span class="s2">&quot;Initial Guess - validation data loss: &quot;</span><span class="p">,</span> <span class="n">vloss</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">test_data_set</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">printout</span><span class="p">(</span><span class="s2">&quot;Initial Guess - test data loss: &quot;</span><span class="p">,</span> <span class="n">tloss</span><span class="p">)</span>

        <span class="c1"># Initialize all the counters.</span>
        <span class="n">checkpoint_counter</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># If we restarted from a checkpoint, we</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_loss</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">vloss_old</span> <span class="o">=</span> <span class="n">vloss</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">vloss_old</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_loss</span>

        <span class="c1"># Perform and log training.</span>
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">last_epoch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">max_number_epochs</span><span class="p">):</span>
            <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

            <span class="c1"># Prepare model for training.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

            <span class="c1"># Process each mini batch and save the training loss.</span>
            <span class="n">training_loss</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="c1"># train sampler</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters_full</span><span class="o">.</span><span class="n">use_horovod</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">sampler</span><span class="p">[</span><span class="s2">&quot;train_sampler&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_epoch</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">batchid</span><span class="p">,</span> <span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span> <span class="ow">in</span> \
                    <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_data_loader</span><span class="p">):</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters_full</span><span class="o">.</span><span class="n">use_gpu</span><span class="p">:</span>

                    <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
                    <span class="n">outputs</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
                <span class="n">training_loss</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__process_mini_batch</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="p">,</span>
                                                           <span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>

            <span class="c1"># Calculate the validation loss. and output it.</span>
            <span class="n">vloss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__validate_network</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="p">,</span>
                                            <span class="bp">self</span><span class="o">.</span><span class="n">validation_data_loader</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters_full</span><span class="o">.</span><span class="n">use_horovod</span><span class="p">:</span>
                <span class="n">vloss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__average_validation</span><span class="p">(</span><span class="n">vloss</span><span class="p">,</span> <span class="s1">&#39;average_loss&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">verbosity</span><span class="p">:</span>
                <span class="n">printout</span><span class="p">(</span><span class="s2">&quot;Epoch: &quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="s2">&quot;validation data loss: &quot;</span><span class="p">,</span> <span class="n">vloss</span><span class="p">)</span>

            <span class="c1"># Mix the DataSets up (this function only does something</span>
            <span class="c1"># in the lazy loading case).</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">use_shuffling_for_samplers</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">mix_datasets</span><span class="p">()</span>

            <span class="c1"># If a scheduler is used, update it.</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">learning_rate_scheduler</span> <span class="o">==</span>\
                        <span class="s2">&quot;ReduceLROnPlateau&quot;</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">vloss</span><span class="p">)</span>

            <span class="c1"># If early stopping is used, check if we need to do something.</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">early_stopping_epochs</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">vloss</span> <span class="o">&lt;</span> <span class="n">vloss_old</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span>
                                        <span class="n">early_stopping_threshold</span><span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">patience_counter</span> <span class="o">=</span> <span class="mi">0</span>
                    <span class="n">vloss_old</span> <span class="o">=</span> <span class="n">vloss</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">patience_counter</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="n">printout</span><span class="p">(</span><span class="s2">&quot;Validation accuracy has not improved enough.&quot;</span><span class="p">)</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">patience_counter</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span>\
                            <span class="n">early_stopping_epochs</span><span class="p">:</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">verbosity</span><span class="p">:</span>
                            <span class="n">printout</span><span class="p">(</span><span class="s2">&quot;Stopping the training, validation &quot;</span>
                                     <span class="s2">&quot;accuracy has not improved for&quot;</span><span class="p">,</span>
                                     <span class="bp">self</span><span class="o">.</span><span class="n">patience_counter</span><span class="p">,</span>
                                     <span class="s2">&quot;epochs.&quot;</span><span class="p">)</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">last_epoch</span> <span class="o">=</span> <span class="n">epoch</span>
                        <span class="k">break</span>

            <span class="c1"># If checkpointing is enabled, we need to checkpoint.</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">checkpoints_each_epoch</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">checkpoint_counter</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">if</span> <span class="n">checkpoint_counter</span> <span class="o">&gt;=</span> \
                        <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">checkpoints_each_epoch</span><span class="p">:</span>
                    <span class="n">printout</span><span class="p">(</span><span class="s2">&quot;Checkpointing training.&quot;</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">last_epoch</span> <span class="o">=</span> <span class="n">epoch</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">last_loss</span> <span class="o">=</span> <span class="n">vloss_old</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">__create_training_checkpoint</span><span class="p">()</span>
                    <span class="n">checkpoint_counter</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">verbosity</span><span class="p">:</span>
                <span class="n">printout</span><span class="p">(</span><span class="s2">&quot;Time for epoch[s]:&quot;</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">)</span>

        <span class="c1"># Calculate final loss.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">final_validation_loss</span> <span class="o">=</span> <span class="n">vloss</span>
        <span class="n">tloss</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">test_data_set</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">tloss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__validate_network</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="p">,</span>
                                            <span class="bp">self</span><span class="o">.</span><span class="n">test_data_loader</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters_full</span><span class="o">.</span><span class="n">use_horovod</span><span class="p">:</span>
                <span class="n">tloss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__average_validation</span><span class="p">(</span><span class="n">tloss</span><span class="p">,</span> <span class="s1">&#39;average_loss&#39;</span><span class="p">)</span>
            <span class="n">printout</span><span class="p">(</span><span class="s2">&quot;Final test data loss: &quot;</span><span class="p">,</span> <span class="n">tloss</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">final_test_loss</span> <span class="o">=</span> <span class="n">tloss</span></div>

    <span class="k">def</span> <span class="nf">__prepare_to_train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer_dict</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Prepare everything for training.&quot;&quot;&quot;</span>
        <span class="c1"># Configure keyword arguments for DataSampler.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters_full</span><span class="o">.</span><span class="n">use_gpu</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;pin_memory&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="c1"># Scale the learning rate according to horovod.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters_full</span><span class="o">.</span><span class="n">use_horovod</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">hvd</span><span class="o">.</span><span class="n">size</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">printout</span><span class="p">(</span><span class="s2">&quot;Rescaling learning rate because multiple workers are&quot;</span>
                         <span class="s2">&quot; used for training.&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">learning_rate</span> \
                    <span class="o">*</span> <span class="n">hvd</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>

        <span class="c1"># Choose an optimizer to use.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">trainingtype</span> <span class="o">==</span> <span class="s2">&quot;SGD&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
                                       <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
                                       <span class="n">weight_decay</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span>
                                       <span class="n">weight_decay</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">trainingtype</span> <span class="o">==</span> <span class="s2">&quot;Adam&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
                                        <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
                                        <span class="n">weight_decay</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span>
                                        <span class="n">weight_decay</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Unsupported training method.&quot;</span><span class="p">)</span>

        <span class="c1"># Load data from pytorch file.</span>
        <span class="k">if</span> <span class="n">optimizer_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span>\
                <span class="n">load_state_dict</span><span class="p">(</span><span class="n">optimizer_dict</span><span class="p">[</span><span class="s1">&#39;optimizer_state_dict&#39;</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">last_epoch</span> <span class="o">=</span> <span class="n">optimizer_dict</span><span class="p">[</span><span class="s1">&#39;epoch&#39;</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">patience_counter</span> <span class="o">=</span> <span class="n">optimizer_dict</span><span class="p">[</span><span class="s1">&#39;early_stopping_counter&#39;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">last_loss</span> <span class="o">=</span> <span class="n">optimizer_dict</span><span class="p">[</span><span class="s1">&#39;early_stopping_last_loss&#39;</span><span class="p">]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters_full</span><span class="o">.</span><span class="n">use_horovod</span><span class="p">:</span>
            <span class="c1"># scaling the batch size for multiGPU per node</span>
            <span class="c1"># self.batch_size= self.batch_size*hvd.local_size()</span>

            <span class="n">compression</span> <span class="o">=</span> <span class="n">hvd</span><span class="o">.</span><span class="n">Compression</span><span class="o">.</span><span class="n">fp16</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters_full</span><span class="o">.</span>\
                <span class="n">running</span><span class="o">.</span><span class="n">use_compression</span> <span class="k">else</span> <span class="n">hvd</span><span class="o">.</span><span class="n">Compression</span><span class="o">.</span><span class="n">none</span>

            <span class="c1"># If lazy loading is used we do not shuffle the data points on</span>
            <span class="c1"># their own, but rather shuffle them</span>
            <span class="c1"># by shuffling the files themselves and then reading file by file</span>
            <span class="c1"># per epoch.</span>
            <span class="c1"># This shuffling is done in the dataset themselves.</span>
            <span class="n">do_shuffle</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">use_shuffling_for_samplers</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">use_lazy_loading</span><span class="p">:</span>
                <span class="n">do_shuffle</span> <span class="o">=</span> <span class="kc">False</span>

            <span class="c1"># Set the data sampler for multiGPU</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">sampler</span><span class="p">[</span><span class="s2">&quot;train_sampler&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span>\
                <span class="n">distributed</span><span class="o">.</span><span class="n">DistributedSampler</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">training_data_set</span><span class="p">,</span>
                                               <span class="n">num_replicas</span><span class="o">=</span><span class="n">hvd</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span>
                                               <span class="n">rank</span><span class="o">=</span><span class="n">hvd</span><span class="o">.</span><span class="n">rank</span><span class="p">(),</span>
                                               <span class="n">shuffle</span><span class="o">=</span><span class="n">do_shuffle</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">sampler</span><span class="p">[</span><span class="s2">&quot;validate_sampler&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span>\
                <span class="n">distributed</span><span class="o">.</span><span class="n">DistributedSampler</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">validation_data_set</span><span class="p">,</span>
                                               <span class="n">num_replicas</span><span class="o">=</span><span class="n">hvd</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span>
                                               <span class="n">rank</span><span class="o">=</span><span class="n">hvd</span><span class="o">.</span><span class="n">rank</span><span class="p">(),</span>
                                               <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">test_data_set</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">sampler</span><span class="p">[</span><span class="s2">&quot;test_sampler&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span>\
                    <span class="n">distributed</span><span class="o">.</span><span class="n">DistributedSampler</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">test_data_set</span><span class="p">,</span>
                                                   <span class="n">num_replicas</span><span class="o">=</span><span class="n">hvd</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span>
                                                   <span class="n">rank</span><span class="o">=</span><span class="n">hvd</span><span class="o">.</span><span class="n">rank</span><span class="p">(),</span>
                                                   <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

            <span class="c1"># broadcaste parameters and optimizer state from root device to</span>
            <span class="c1"># other devices</span>
            <span class="n">hvd</span><span class="o">.</span><span class="n">broadcast_parameters</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">root_rank</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">hvd</span><span class="o">.</span><span class="n">broadcast_optimizer_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">root_rank</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

            <span class="c1"># Wraps the opimizer for multiGPU operation</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">hvd</span><span class="o">.</span><span class="n">DistributedOptimizer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span>
                                                      <span class="n">named_parameters</span><span class="o">=</span>
                                                      <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="o">.</span>
                                                      <span class="n">named_parameters</span><span class="p">(),</span>
                                                      <span class="n">compression</span><span class="o">=</span><span class="n">compression</span><span class="p">,</span>
                                                      <span class="n">op</span><span class="o">=</span><span class="n">hvd</span><span class="o">.</span><span class="n">Average</span><span class="p">)</span>

        <span class="c1"># Instantiate the learning rate scheduler, if necessary.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">learning_rate_scheduler</span> <span class="o">==</span> <span class="s2">&quot;ReduceLROnPlateau&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span>\
                <span class="n">lr_scheduler</span><span class="o">.</span><span class="n">ReduceLROnPlateau</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span>
                                               <span class="n">patience</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span>
                                               <span class="n">learning_rate_patience</span><span class="p">,</span>
                                               <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;min&quot;</span><span class="p">,</span>
                                               <span class="n">factor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span>
                                               <span class="n">learning_rate_decay</span><span class="p">,</span>
                                               <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">learning_rate_scheduler</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">pass</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Unsupported learning rate schedule.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">optimizer_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span>\
                <span class="n">load_state_dict</span><span class="p">(</span><span class="n">optimizer_dict</span><span class="p">[</span><span class="s1">&#39;lr_scheduler_state_dict&#39;</span><span class="p">])</span>

        <span class="c1"># If lazy loading is used we do not shuffle the data points on their</span>
        <span class="c1"># own, but rather shuffle them</span>
        <span class="c1"># by shuffling the files themselves and then reading file by file per</span>
        <span class="c1"># epoch.</span>
        <span class="c1"># This shuffling is done in the dataset themselves.</span>
        <span class="n">do_shuffle</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">use_shuffling_for_samplers</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">use_lazy_loading</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters_full</span><span class="o">.</span>\
                <span class="n">use_horovod</span><span class="p">:</span>
            <span class="n">do_shuffle</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># Prepare data loaders.(look into mini-batch size)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_data_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">training_data_set</span><span class="p">,</span>
                                               <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span>
                                               <span class="n">mini_batch_size</span><span class="p">,</span>
                                               <span class="n">sampler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span>
                                               <span class="n">sampler</span><span class="p">[</span><span class="s2">&quot;train_sampler&quot;</span><span class="p">],</span>
                                               <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">kwargs</span><span class="p">,</span>
                                               <span class="n">shuffle</span><span class="o">=</span><span class="n">do_shuffle</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">validation_data_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">validation_data_set</span><span class="p">,</span>
                                                 <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span>
                                                 <span class="n">mini_batch_size</span> <span class="o">*</span> <span class="mi">1</span><span class="p">,</span>
                                                 <span class="n">sampler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span>
                                                 <span class="n">sampler</span><span class="p">[</span><span class="s2">&quot;validate_sampler&quot;</span><span class="p">],</span>
                                                 <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">test_data_set</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">test_data_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">test_data_set</span><span class="p">,</span>
                                               <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span>
                                               <span class="n">mini_batch_size</span> <span class="o">*</span> <span class="mi">1</span><span class="p">,</span>
                                               <span class="n">sampler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span>
                                               <span class="n">sampler</span><span class="p">[</span><span class="s2">&quot;test_sampler&quot;</span><span class="p">],</span>
                                               <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__process_mini_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">,</span> <span class="n">input_data</span><span class="p">,</span> <span class="n">target_data</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Process a mini batch.&quot;&quot;&quot;</span>
        <span class="n">prediction</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">calculate_loss</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">target_data</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">__validate_network</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">,</span> <span class="n">vdl</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Validate a network, using test or validation data.&quot;&quot;&quot;</span>
        <span class="n">network</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">validation_loss</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">vdl</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters_full</span><span class="o">.</span><span class="n">use_gpu</span><span class="p">:</span>
                    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
                    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
                <span class="n">prediction</span> <span class="o">=</span> <span class="n">network</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                <span class="n">validation_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">network</span><span class="o">.</span><span class="n">calculate_loss</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
                                       <span class="o">.</span><span class="n">item</span><span class="p">())</span>

        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">validation_loss</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__create_training_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a checkpoint during training.</span>

<span class="sd">        Follows https://pytorch.org/tutorials/recipes/recipes/saving_and_</span>
<span class="sd">        loading_a_general_checkpoint.html to some degree.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">network_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">checkpoint_name</span> \
            <span class="o">+</span> <span class="s2">&quot;_network.pth&quot;</span>
        <span class="n">iscaler_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">checkpoint_name</span> \
            <span class="o">+</span> <span class="s2">&quot;_iscaler.pkl&quot;</span>
        <span class="n">oscaler_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">checkpoint_name</span> \
            <span class="o">+</span> <span class="s2">&quot;_oscaler.pkl&quot;</span>
        <span class="n">param_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">checkpoint_name</span> \
            <span class="o">+</span> <span class="s2">&quot;_params.pkl&quot;</span>
        <span class="n">optimizer_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">checkpoint_name</span> \
            <span class="o">+</span> <span class="s2">&quot;_optimizer.pth&quot;</span>

        <span class="c1"># First we save the objects we would also save for inference.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">input_data_scaler</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">iscaler_name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">output_data_scaler</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">oscaler_name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">parameters_full</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">param_name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">save_network</span><span class="p">(</span><span class="n">network_name</span><span class="p">)</span>

        <span class="c1"># Next, we save all the other objects.</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters_full</span><span class="o">.</span><span class="n">use_horovod</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">hvd</span><span class="o">.</span><span class="n">rank</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">return</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">save_dict</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s1">&#39;epoch&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_epoch</span><span class="p">,</span>
                <span class="s1">&#39;optimizer_state_dict&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                <span class="s1">&#39;early_stopping_counter&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">patience_counter</span><span class="p">,</span>
                <span class="s1">&#39;early_stopping_last_loss&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_loss</span>
            <span class="p">}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">save_dict</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s1">&#39;epoch&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_epoch</span><span class="p">,</span>
                <span class="s1">&#39;optimizer_state_dict&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                <span class="s1">&#39;lr_scheduler_state_dict&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                <span class="s1">&#39;early_stopping_counter&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">patience_counter</span><span class="p">,</span>
                <span class="s1">&#39;early_stopping_last_loss&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_loss</span>
            <span class="p">}</span>

        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">save_dict</span><span class="p">,</span> <span class="n">optimizer_name</span><span class="p">,</span>
                   <span class="n">_use_new_zipfile_serialization</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">__average_validation</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Average validation over multiple parallel processes.&quot;&quot;&quot;</span>
        <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
        <span class="n">avg_loss</span> <span class="o">=</span> <span class="n">hvd</span><span class="o">.</span><span class="n">allreduce</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">op</span><span class="o">=</span><span class="n">hvd</span><span class="o">.</span><span class="n">Average</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">avg_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span></div>
</pre></div>

           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, HZDR.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>